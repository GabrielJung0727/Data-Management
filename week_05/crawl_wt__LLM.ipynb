{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHaGw2ZdgWnhm199TyZMGG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8bae6eb490a145d784088837c7e13330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_63c3f4adaba248579908321daa22bd0d"
          }
        },
        "aec1a31d5a1846ecb263d809f056eda4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c7787bdd5a54bff959feb262d76f959",
            "placeholder": "​",
            "style": "IPY_MODEL_5096495e742b45e5b9041cc5f3ad34e3",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "160173a2704a4497a08abd155ae3ccde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_86bfe5cf39ce44feab938f41e96e4e72",
            "placeholder": "​",
            "style": "IPY_MODEL_0692b233e40f4a10912e5dba422a53e7",
            "value": ""
          }
        },
        "b6ed7c7d5eb34651a6db4afc79edf5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_cf8b85df642148e08309612029ac8153",
            "style": "IPY_MODEL_bfe97072de4d463b95e6fed293361c71",
            "value": true
          }
        },
        "9f0396f9beaf4410b078331aa2ee0140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_c867caa8acb4440293d65b4b4588a51c",
            "style": "IPY_MODEL_2039313168a34faead964cc615294099",
            "tooltip": ""
          }
        },
        "c00a645ef37e4ac4a4308a3df8ec05d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c4fe7ed585042a381f1d50d8bf90455",
            "placeholder": "​",
            "style": "IPY_MODEL_ce8caaface1b438fa90050d0a3f3c8b3",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "63c3f4adaba248579908321daa22bd0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "6c7787bdd5a54bff959feb262d76f959": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5096495e742b45e5b9041cc5f3ad34e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86bfe5cf39ce44feab938f41e96e4e72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0692b233e40f4a10912e5dba422a53e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf8b85df642148e08309612029ac8153": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfe97072de4d463b95e6fed293361c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c867caa8acb4440293d65b4b4588a51c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2039313168a34faead964cc615294099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "9c4fe7ed585042a381f1d50d8bf90455": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce8caaface1b438fa90050d0a3f3c8b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64e1be2531d54e7dbb33df62482d406e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_546013082db9460098121e9902e7bab1",
            "placeholder": "​",
            "style": "IPY_MODEL_f26d0d6a4d4f48d79b44e514a069ba87",
            "value": "Connecting..."
          }
        },
        "546013082db9460098121e9902e7bab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f26d0d6a4d4f48d79b44e514a069ba87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "418075173bdb4e03ad7e529c4ac68c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5bea75d09953425093ffd1302d7112c4",
              "IPY_MODEL_12af88c45d714fd3b4b4fb103a375c67",
              "IPY_MODEL_47366e24736e4629862ade0d8704d6ea"
            ],
            "layout": "IPY_MODEL_7c07fc3120bb4019811e0ffabf811745"
          }
        },
        "5bea75d09953425093ffd1302d7112c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73eab7b9e233452eb09715a71a9bb3c6",
            "placeholder": "​",
            "style": "IPY_MODEL_dc7c620625014fa7b8517f361bee3dfe",
            "value": "deepseek-coder-1.3b-base.Q4_K_M.gguf: 100%"
          }
        },
        "12af88c45d714fd3b4b4fb103a375c67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_457c302265c4451bb6cc165f0bbc05da",
            "max": 873582624,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5638452fa4754c429f2f10824101602b",
            "value": 873582624
          }
        },
        "47366e24736e4629862ade0d8704d6ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a233254cf22c4a6daa1801b272b33246",
            "placeholder": "​",
            "style": "IPY_MODEL_709b9ae3e4624212af88cc6590b3b495",
            "value": " 874M/874M [00:10&lt;00:00, 93.8MB/s]"
          }
        },
        "7c07fc3120bb4019811e0ffabf811745": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73eab7b9e233452eb09715a71a9bb3c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc7c620625014fa7b8517f361bee3dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "457c302265c4451bb6cc165f0bbc05da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5638452fa4754c429f2f10824101602b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a233254cf22c4a6daa1801b272b33246": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "709b9ae3e4624212af88cc6590b3b495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ancestor9/2025_Spring_Data-Management/blob/main/week_05/crawl_wt__LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필수 라이브러리 설치\n",
        "%%capture\n",
        "!pip install -q crawl4ai llama-cpp-python\n",
        "!pip install -q playwright\n",
        "!playwright install chromium"
      ],
      "metadata": {
        "id": "rRts7-ONgsEA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hugging Face CLI 설치\n",
        "!pip install -q huggingface_hub\n",
        "\n",
        "# 로그인\n",
        "from huggingface_hub import login\n",
        "login()  # 발급받은 토큰 입력\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "8bae6eb490a145d784088837c7e13330",
            "aec1a31d5a1846ecb263d809f056eda4",
            "160173a2704a4497a08abd155ae3ccde",
            "b6ed7c7d5eb34651a6db4afc79edf5ca",
            "9f0396f9beaf4410b078331aa2ee0140",
            "c00a645ef37e4ac4a4308a3df8ec05d8",
            "63c3f4adaba248579908321daa22bd0d",
            "6c7787bdd5a54bff959feb262d76f959",
            "5096495e742b45e5b9041cc5f3ad34e3",
            "86bfe5cf39ce44feab938f41e96e4e72",
            "0692b233e40f4a10912e5dba422a53e7",
            "cf8b85df642148e08309612029ac8153",
            "bfe97072de4d463b95e6fed293361c71",
            "c867caa8acb4440293d65b4b4588a51c",
            "2039313168a34faead964cc615294099",
            "9c4fe7ed585042a381f1d50d8bf90455",
            "ce8caaface1b438fa90050d0a3f3c8b3",
            "64e1be2531d54e7dbb33df62482d406e",
            "546013082db9460098121e9902e7bab1",
            "f26d0d6a4d4f48d79b44e514a069ba87"
          ]
        },
        "id": "eSvOcsxajotA",
        "outputId": "02829cf9-3218-43a6-cf35-887cdac8ff36"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bae6eb490a145d784088837c7e13330"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import Llama\n",
        "\n",
        "# 모델 파일 다운로드\n",
        "model_path = hf_hub_download(\n",
        "    repo_id=\"TheBloke/deepseek-coder-1.3b-base-GGUF\",\n",
        "    filename=\"deepseek-coder-1.3b-base.Q4_K_M.gguf\"\n",
        ")\n",
        "\n",
        "# 모델 로드\n",
        "llm = Llama(model_path=model_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "418075173bdb4e03ad7e529c4ac68c00",
            "5bea75d09953425093ffd1302d7112c4",
            "12af88c45d714fd3b4b4fb103a375c67",
            "47366e24736e4629862ade0d8704d6ea",
            "7c07fc3120bb4019811e0ffabf811745",
            "73eab7b9e233452eb09715a71a9bb3c6",
            "dc7c620625014fa7b8517f361bee3dfe",
            "457c302265c4451bb6cc165f0bbc05da",
            "5638452fa4754c429f2f10824101602b",
            "a233254cf22c4a6daa1801b272b33246",
            "709b9ae3e4624212af88cc6590b3b495"
          ]
        },
        "id": "Yg6LXmNgj52K",
        "outputId": "9efb6c19-fc93-4904-a4bf-d649e9f7e60e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "deepseek-coder-1.3b-base.Q4_K_M.gguf:   0%|          | 0.00/874M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "418075173bdb4e03ad7e529c4ac68c00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 22 key-value pairs and 219 tensors from /root/.cache/huggingface/hub/models--TheBloke--deepseek-coder-1.3b-base-GGUF/snapshots/ec89dd32c0a17bd56d27eccca7d6e4195c0f615d/deepseek-coder-1.3b-base.Q4_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = deepseek-ai_deepseek-coder-1.3b-base\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 16384\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 2048\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 24\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 5504\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 16\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 16\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 100000.000000\n",
            "llama_model_loader: - kv  11:                    llama.rope.scale_linear f32              = 4.000000\n",
            "llama_model_loader: - kv  12:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,32256]   = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.scores arr[f32,32256]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,32256]   = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,31757]   = [\"Ġ Ġ\", \"Ġ t\", \"Ġ a\", \"i n\", \"h e...\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 32013\n",
            "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 32014\n",
            "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 32014\n",
            "llama_model_loader: - kv  21:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   49 tensors\n",
            "llama_model_loader: - type q5_0:   12 tensors\n",
            "llama_model_loader: - type q8_0:   12 tensors\n",
            "llama_model_loader: - type q4_K:  133 tensors\n",
            "llama_model_loader: - type q6_K:   13 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 831.88 MiB (5.18 BPW) \n",
            "load: missing pre-tokenizer type, using: 'default'\n",
            "load:                                             \n",
            "load: ************************************        \n",
            "load: GENERATION QUALITY WILL BE DEGRADED!        \n",
            "load: CONSIDER REGENERATING THE MODEL             \n",
            "load: ************************************        \n",
            "load:                                             \n",
            "init_tokenizer: initializing tokenizer for type 2\n",
            "load: control-looking token:  32015 '<｜fim▁hole｜>' was not control-type; this is probably a bug in the model. its type will be overridden\n",
            "load: control-looking token:  32017 '<｜fim▁end｜>' was not control-type; this is probably a bug in the model. its type will be overridden\n",
            "load: control-looking token:  32016 '<｜fim▁begin｜>' was not control-type; this is probably a bug in the model. its type will be overridden\n",
            "load: control token:  32015 '<｜fim▁hole｜>' is not marked as EOG\n",
            "load: control token:  32014 '<｜end▁of▁sentence｜>' is not marked as EOG\n",
            "load: control token:  32017 '<｜fim▁end｜>' is not marked as EOG\n",
            "load: control token:  32016 '<｜fim▁begin｜>' is not marked as EOG\n",
            "load: control token:  32013 '<｜begin▁of▁sentence｜>' is not marked as EOG\n",
            "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "load: special tokens cache size = 239\n",
            "load: token to piece cache size = 0.1792 MB\n",
            "print_info: arch             = llama\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 16384\n",
            "print_info: n_embd           = 2048\n",
            "print_info: n_layer          = 24\n",
            "print_info: n_head           = 16\n",
            "print_info: n_head_kv        = 16\n",
            "print_info: n_rot            = 128\n",
            "print_info: n_swa            = 0\n",
            "print_info: n_embd_head_k    = 128\n",
            "print_info: n_embd_head_v    = 128\n",
            "print_info: n_gqa            = 1\n",
            "print_info: n_embd_k_gqa     = 2048\n",
            "print_info: n_embd_v_gqa     = 2048\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-06\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: f_attn_scale     = 0.0e+00\n",
            "print_info: n_ff             = 5504\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 0\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 100000.0\n",
            "print_info: freq_scale_train = 0.25\n",
            "print_info: n_ctx_orig_yarn  = 16384\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: ssm_d_conv       = 0\n",
            "print_info: ssm_d_inner      = 0\n",
            "print_info: ssm_d_state      = 0\n",
            "print_info: ssm_dt_rank      = 0\n",
            "print_info: ssm_dt_b_c_rms   = 0\n",
            "print_info: model type       = ?B\n",
            "print_info: model params     = 1.35 B\n",
            "print_info: general.name     = deepseek-ai_deepseek-coder-1.3b-base\n",
            "print_info: vocab type       = BPE\n",
            "print_info: n_vocab          = 32256\n",
            "print_info: n_merges         = 31757\n",
            "print_info: BOS token        = 32013 '<｜begin▁of▁sentence｜>'\n",
            "print_info: EOS token        = 32014 '<｜end▁of▁sentence｜>'\n",
            "print_info: EOT token        = 32014 '<｜end▁of▁sentence｜>'\n",
            "print_info: PAD token        = 32014 '<｜end▁of▁sentence｜>'\n",
            "print_info: LF token         = 185 'Ċ'\n",
            "print_info: FIM PRE token    = 32016 '<｜fim▁begin｜>'\n",
            "print_info: FIM SUF token    = 32015 '<｜fim▁hole｜>'\n",
            "print_info: FIM MID token    = 32017 '<｜fim▁end｜>'\n",
            "print_info: EOG token        = 32014 '<｜end▁of▁sentence｜>'\n",
            "print_info: max token length = 128\n",
            "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
            "load_tensors: layer   0 assigned to device CPU\n",
            "load_tensors: layer   1 assigned to device CPU\n",
            "load_tensors: layer   2 assigned to device CPU\n",
            "load_tensors: layer   3 assigned to device CPU\n",
            "load_tensors: layer   4 assigned to device CPU\n",
            "load_tensors: layer   5 assigned to device CPU\n",
            "load_tensors: layer   6 assigned to device CPU\n",
            "load_tensors: layer   7 assigned to device CPU\n",
            "load_tensors: layer   8 assigned to device CPU\n",
            "load_tensors: layer   9 assigned to device CPU\n",
            "load_tensors: layer  10 assigned to device CPU\n",
            "load_tensors: layer  11 assigned to device CPU\n",
            "load_tensors: layer  12 assigned to device CPU\n",
            "load_tensors: layer  13 assigned to device CPU\n",
            "load_tensors: layer  14 assigned to device CPU\n",
            "load_tensors: layer  15 assigned to device CPU\n",
            "load_tensors: layer  16 assigned to device CPU\n",
            "load_tensors: layer  17 assigned to device CPU\n",
            "load_tensors: layer  18 assigned to device CPU\n",
            "load_tensors: layer  19 assigned to device CPU\n",
            "load_tensors: layer  20 assigned to device CPU\n",
            "load_tensors: layer  21 assigned to device CPU\n",
            "load_tensors: layer  22 assigned to device CPU\n",
            "load_tensors: layer  23 assigned to device CPU\n",
            "load_tensors: layer  24 assigned to device CPU\n",
            "load_tensors: tensor 'token_embd.weight' (q4_K) (and 218 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
            "load_tensors:   CPU_Mapped model buffer size =   831.88 MiB\n",
            ".......................................................................................\n",
            "llama_init_from_model: n_seq_max     = 1\n",
            "llama_init_from_model: n_ctx         = 512\n",
            "llama_init_from_model: n_ctx_per_seq = 512\n",
            "llama_init_from_model: n_batch       = 512\n",
            "llama_init_from_model: n_ubatch      = 512\n",
            "llama_init_from_model: flash_attn    = 0\n",
            "llama_init_from_model: freq_base     = 100000.0\n",
            "llama_init_from_model: freq_scale    = 0.25\n",
            "llama_init_from_model: n_ctx_per_seq (512) < n_ctx_train (16384) -- the full capacity of the model will not be utilized\n",
            "llama_kv_cache_init: kv_size = 512, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 24, can_shift = 1\n",
            "llama_kv_cache_init: layer 0: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 1: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 2: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 3: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 4: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 5: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 6: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 7: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 8: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 9: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 10: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 11: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 12: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 13: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 14: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 15: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 16: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 17: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 18: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 19: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 20: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 21: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 22: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 23: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init:        CPU KV buffer size =    96.00 MiB\n",
            "llama_init_from_model: KV self size  =   96.00 MiB, K (f16):   48.00 MiB, V (f16):   48.00 MiB\n",
            "llama_init_from_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_init_from_model:        CPU compute buffer size =    67.00 MiB\n",
            "llama_init_from_model: graph nodes  = 774\n",
            "llama_init_from_model: graph splits = 1\n",
            "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
            "Model metadata: {'tokenizer.ggml.padding_token_id': '32014', 'tokenizer.ggml.eos_token_id': '32014', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'general.architecture': 'llama', 'llama.rope.freq_base': '100000.000000', 'llama.context_length': '16384', 'general.name': 'deepseek-ai_deepseek-coder-1.3b-base', 'llama.embedding_length': '2048', 'llama.feed_forward_length': '5504', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '32013', 'llama.attention.head_count': '16', 'llama.block_count': '24', 'llama.attention.head_count_kv': '16', 'llama.rope.scale_linear': '4.000000', 'general.file_type': '15'}\n",
            "Using fallback chat format: llama-2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvAGYSR_gmS2",
        "outputId": "37d09e77-c118-4db2-c1c6-09e1953991ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INIT].... → Crawl4AI 0.5.0.post8\n",
            "[FETCH]... ↓ https://client.com/products... | Status: True | Time: 2.56s\n",
            "[SCRAPE].. ◆ https://client.com/products... | Time: 0.023s\n",
            "[COMPLETE] ● https://client.com/products... | Status: True | Total: 2.61s\n",
            "[![](https://files.efty.com/market/uploads/logo/8e96ab2ee4d5c6107e4ef52955c9b51d.jpg)](https://www.oxley.com)\n",
            "### [www.oxley.com](https://www.oxley.com \"www.oxley.com\") > [Domain overview](https://www.oxley.com/search/) > client.com\n",
            "## client.com\n",
            "This premium domain name is available for purchase! \n",
            "[Make an offer](https://client.com/products)\n",
            "![](https://client.com/img/efty_market_themes/borgen/divider.png)\n",
            "Make an offer on\n",
            "### client.com\n",
            "To make an offer, please complete the form below \n",
            "Name *\n",
            "Email *\n",
            "Phone number\n",
            "Offer Offers can only be made in USD\n",
            "Message\n",
            "[ Contact ](https://client.com/contact/ \"Contact\")\n",
            "![](https://client.com/img/loading_black_bg_big.gif)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "from crawl4ai import AsyncWebCrawler\n",
        "from llama_cpp import Llama\n",
        "\n",
        "# LLM 로드 (로컬 모델 파일 필요)\n",
        "\n",
        "async def main():\n",
        "    async with AsyncWebCrawler() as crawler:\n",
        "        result = await crawler.arun(\n",
        "            url=\"https://client.com/products\",\n",
        "            strategy=\"llm\",\n",
        "            llm=llm,\n",
        "            prompt=\"Extract product names, prices, and SKUs into JSON.\"\n",
        "        )\n",
        "        print(result.markdown)  # 또는 result.extracted_data\n",
        "\n",
        "# 비동기 실행\n",
        "await main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from llama_cpp import Llama\n",
        "\n",
        "# 1. User-Agent 설정\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/122.0.0.0 Safari/537.36\"\n",
        "}\n",
        "\n",
        "# 2. CNN 페이지 가져오기\n",
        "url = \"https://edition.cnn.com/world\"\n",
        "response = requests.get(url, headers=headers)\n",
        "html = response.text\n",
        "\n",
        "# 3. LLM 모델 로딩 (Colab에 이미 다운로드되어 있다고 가정)\n",
        "\n",
        "llm = Llama(model_path=model_path, n_ctx=4096)\n",
        "\n",
        "# 4. HTML 요약 요청\n",
        "output = llm.create_completion(prompt=f\"Summarize the following HTML page:\\n{html[:4000]}\")\n",
        "print(output['choices'][0]['text'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCceUZqBksbP",
        "outputId": "1010b6d8-d3d6-4e2a-fd02-aa6b36212392"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 22 key-value pairs and 219 tensors from /root/.cache/huggingface/hub/models--TheBloke--deepseek-coder-1.3b-base-GGUF/snapshots/ec89dd32c0a17bd56d27eccca7d6e4195c0f615d/deepseek-coder-1.3b-base.Q4_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = deepseek-ai_deepseek-coder-1.3b-base\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 16384\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 2048\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 24\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 5504\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 16\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 16\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 100000.000000\n",
            "llama_model_loader: - kv  11:                    llama.rope.scale_linear f32              = 4.000000\n",
            "llama_model_loader: - kv  12:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,32256]   = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.scores arr[f32,32256]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,32256]   = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,31757]   = [\"Ġ Ġ\", \"Ġ t\", \"Ġ a\", \"i n\", \"h e...\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 32013\n",
            "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 32014\n",
            "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 32014\n",
            "llama_model_loader: - kv  21:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   49 tensors\n",
            "llama_model_loader: - type q5_0:   12 tensors\n",
            "llama_model_loader: - type q8_0:   12 tensors\n",
            "llama_model_loader: - type q4_K:  133 tensors\n",
            "llama_model_loader: - type q6_K:   13 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 831.88 MiB (5.18 BPW) \n",
            "load: missing pre-tokenizer type, using: 'default'\n",
            "load:                                             \n",
            "load: ************************************        \n",
            "load: GENERATION QUALITY WILL BE DEGRADED!        \n",
            "load: CONSIDER REGENERATING THE MODEL             \n",
            "load: ************************************        \n",
            "load:                                             \n",
            "init_tokenizer: initializing tokenizer for type 2\n",
            "load: control-looking token:  32015 '<｜fim▁hole｜>' was not control-type; this is probably a bug in the model. its type will be overridden\n",
            "load: control-looking token:  32017 '<｜fim▁end｜>' was not control-type; this is probably a bug in the model. its type will be overridden\n",
            "load: control-looking token:  32016 '<｜fim▁begin｜>' was not control-type; this is probably a bug in the model. its type will be overridden\n",
            "load: control token:  32015 '<｜fim▁hole｜>' is not marked as EOG\n",
            "load: control token:  32014 '<｜end▁of▁sentence｜>' is not marked as EOG\n",
            "load: control token:  32017 '<｜fim▁end｜>' is not marked as EOG\n",
            "load: control token:  32016 '<｜fim▁begin｜>' is not marked as EOG\n",
            "load: control token:  32013 '<｜begin▁of▁sentence｜>' is not marked as EOG\n",
            "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "load: special tokens cache size = 239\n",
            "load: token to piece cache size = 0.1792 MB\n",
            "print_info: arch             = llama\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 16384\n",
            "print_info: n_embd           = 2048\n",
            "print_info: n_layer          = 24\n",
            "print_info: n_head           = 16\n",
            "print_info: n_head_kv        = 16\n",
            "print_info: n_rot            = 128\n",
            "print_info: n_swa            = 0\n",
            "print_info: n_embd_head_k    = 128\n",
            "print_info: n_embd_head_v    = 128\n",
            "print_info: n_gqa            = 1\n",
            "print_info: n_embd_k_gqa     = 2048\n",
            "print_info: n_embd_v_gqa     = 2048\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-06\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: f_attn_scale     = 0.0e+00\n",
            "print_info: n_ff             = 5504\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 0\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 100000.0\n",
            "print_info: freq_scale_train = 0.25\n",
            "print_info: n_ctx_orig_yarn  = 16384\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: ssm_d_conv       = 0\n",
            "print_info: ssm_d_inner      = 0\n",
            "print_info: ssm_d_state      = 0\n",
            "print_info: ssm_dt_rank      = 0\n",
            "print_info: ssm_dt_b_c_rms   = 0\n",
            "print_info: model type       = ?B\n",
            "print_info: model params     = 1.35 B\n",
            "print_info: general.name     = deepseek-ai_deepseek-coder-1.3b-base\n",
            "print_info: vocab type       = BPE\n",
            "print_info: n_vocab          = 32256\n",
            "print_info: n_merges         = 31757\n",
            "print_info: BOS token        = 32013 '<｜begin▁of▁sentence｜>'\n",
            "print_info: EOS token        = 32014 '<｜end▁of▁sentence｜>'\n",
            "print_info: EOT token        = 32014 '<｜end▁of▁sentence｜>'\n",
            "print_info: PAD token        = 32014 '<｜end▁of▁sentence｜>'\n",
            "print_info: LF token         = 185 'Ċ'\n",
            "print_info: FIM PRE token    = 32016 '<｜fim▁begin｜>'\n",
            "print_info: FIM SUF token    = 32015 '<｜fim▁hole｜>'\n",
            "print_info: FIM MID token    = 32017 '<｜fim▁end｜>'\n",
            "print_info: EOG token        = 32014 '<｜end▁of▁sentence｜>'\n",
            "print_info: max token length = 128\n",
            "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
            "load_tensors: layer   0 assigned to device CPU\n",
            "load_tensors: layer   1 assigned to device CPU\n",
            "load_tensors: layer   2 assigned to device CPU\n",
            "load_tensors: layer   3 assigned to device CPU\n",
            "load_tensors: layer   4 assigned to device CPU\n",
            "load_tensors: layer   5 assigned to device CPU\n",
            "load_tensors: layer   6 assigned to device CPU\n",
            "load_tensors: layer   7 assigned to device CPU\n",
            "load_tensors: layer   8 assigned to device CPU\n",
            "load_tensors: layer   9 assigned to device CPU\n",
            "load_tensors: layer  10 assigned to device CPU\n",
            "load_tensors: layer  11 assigned to device CPU\n",
            "load_tensors: layer  12 assigned to device CPU\n",
            "load_tensors: layer  13 assigned to device CPU\n",
            "load_tensors: layer  14 assigned to device CPU\n",
            "load_tensors: layer  15 assigned to device CPU\n",
            "load_tensors: layer  16 assigned to device CPU\n",
            "load_tensors: layer  17 assigned to device CPU\n",
            "load_tensors: layer  18 assigned to device CPU\n",
            "load_tensors: layer  19 assigned to device CPU\n",
            "load_tensors: layer  20 assigned to device CPU\n",
            "load_tensors: layer  21 assigned to device CPU\n",
            "load_tensors: layer  22 assigned to device CPU\n",
            "load_tensors: layer  23 assigned to device CPU\n",
            "load_tensors: layer  24 assigned to device CPU\n",
            "load_tensors: tensor 'token_embd.weight' (q4_K) (and 218 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
            "load_tensors:   CPU_Mapped model buffer size =   831.88 MiB\n",
            ".......................................................................................\n",
            "llama_init_from_model: n_seq_max     = 1\n",
            "llama_init_from_model: n_ctx         = 4096\n",
            "llama_init_from_model: n_ctx_per_seq = 4096\n",
            "llama_init_from_model: n_batch       = 512\n",
            "llama_init_from_model: n_ubatch      = 512\n",
            "llama_init_from_model: flash_attn    = 0\n",
            "llama_init_from_model: freq_base     = 100000.0\n",
            "llama_init_from_model: freq_scale    = 0.25\n",
            "llama_init_from_model: n_ctx_per_seq (4096) < n_ctx_train (16384) -- the full capacity of the model will not be utilized\n",
            "llama_kv_cache_init: kv_size = 4096, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 24, can_shift = 1\n",
            "llama_kv_cache_init: layer 0: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 1: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 2: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 3: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 4: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 5: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 6: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 7: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 8: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 9: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 10: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 11: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 12: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 13: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 14: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 15: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 16: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 17: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 18: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 19: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 20: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 21: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 22: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init: layer 23: n_embd_k_gqa = 2048, n_embd_v_gqa = 2048\n",
            "llama_kv_cache_init:        CPU KV buffer size =   768.00 MiB\n",
            "llama_init_from_model: KV self size  =  768.00 MiB, K (f16):  384.00 MiB, V (f16):  384.00 MiB\n",
            "llama_init_from_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_init_from_model:        CPU compute buffer size =   152.01 MiB\n",
            "llama_init_from_model: graph nodes  = 774\n",
            "llama_init_from_model: graph splits = 1\n",
            "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
            "Model metadata: {'tokenizer.ggml.padding_token_id': '32014', 'tokenizer.ggml.eos_token_id': '32014', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'general.architecture': 'llama', 'llama.rope.freq_base': '100000.000000', 'llama.context_length': '16384', 'general.name': 'deepseek-ai_deepseek-coder-1.3b-base', 'llama.embedding_length': '2048', 'llama.feed_forward_length': '5504', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '32013', 'llama.attention.head_count': '16', 'llama.block_count': '24', 'llama.attention.head_count_kv': '16', 'llama.rope.scale_linear': '4.000000', 'general.file_type': '15'}\n",
            "Using fallback chat format: llama-2\n",
            "llama_perf_context_print:        load time =  173649.59 ms\n",
            "llama_perf_context_print: prompt eval time =  173648.83 ms /  1908 tokens (   91.01 ms per token,    10.99 tokens per second)\n",
            "llama_perf_context_print:        eval time =    3514.64 ms /    15 runs   (  234.31 ms per token,     4.27 tokens per second)\n",
            "llama_perf_context_print:       total time =  177172.97 ms /  1923 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "purple-600:#5d368cff;--prim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8D54ZliOlN85",
        "outputId": "16f59a7b-9708-4ced-b101-d870edc4593d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'cmpl-f64681c0-b2f5-4009-945e-3931ddfb7d4c',\n",
              " 'object': 'text_completion',\n",
              " 'created': 1743263402,\n",
              " 'model': '/root/.cache/huggingface/hub/models--TheBloke--deepseek-coder-1.3b-base-GGUF/snapshots/ec89dd32c0a17bd56d27eccca7d6e4195c0f615d/deepseek-coder-1.3b-base.Q4_K_M.gguf',\n",
              " 'choices': [{'text': 'purple-600:#5d368cff;--prim',\n",
              "   'index': 0,\n",
              "   'logprobs': None,\n",
              "   'finish_reason': 'length'}],\n",
              " 'usage': {'prompt_tokens': 1908,\n",
              "  'completion_tokens': 16,\n",
              "  'total_tokens': 1924}}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# 1. CNN 페이지 HTML을 받아서\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "# 2. 주요 기사 제목, 문장 추출\n",
        "text = soup.get_text(separator='\\n')\n",
        "clean_text = \"\\n\".join(line.strip() for line in text.splitlines() if len(line.strip()) > 30)\n",
        "\n",
        "# 3. 길이 제한 (n_ctx 4096 기준)\n",
        "truncated = clean_text[:3500]\n",
        "truncated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "6QdHPvyunfKR",
        "outputId": "daeb7661-42cd-499a-d29a-2abcfdb4d2a0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"World news - breaking news, video, headlines and opinion | CNN\\n1. How relevant is this ad to you?\\n2. Did you encounter any technical issues?\\nVideo player was slow to load content\\nAd froze or did not finish loading\\nVideo content did not start after ad\\nAd prevented/slowed the page from loading\\nContent moved around while ad loaded\\nAd was repetitive to ads I've seen previously\\nYour effort and contribution in providing this feedback is much\\nChasing Life with Dr. Sanjay Gupta\\nThe Assignment with Audie Cornish\\nAll There Is with Anderson Cooper\\nDesperate search for survivors in Myanmar as death toll surges past 1,600\\nThe world’s youngest country fought for decades to govern itself. Now it’s on the cusp of another civil war\\nHow to help those affected by the Myanmar earthquake\\nVoices are starting to emerge from quake devastated Myanmar. Here’s what we are hearing\\nAid workers reported killed and missing in Gaza as Israeli blockade nears one month\\nDanish foreign minister scolds Trump administration for its criticism of Denmark and Greenland\\nFrom death row to exile, Iranian-Kurdish rapper gives firsthand account of what he calls ‘severe torture’ in Iranian prison\\nEuropean bid for Ukraine ‘reassurance’ force is fraught with risk\\nMeet the conservationist saving gorillas in Uganda’s ‘impenetrable forest’\\nVast areas of Australia’s Queensland under water after ‘unprecedented’ flooding\\nUS defense chief Hegseth vows to counter ‘China’s aggression’ on first Asia visit\\nThese 60-year-old geckos could be the world’s oldest\\nEuropean leaders say now not the time to lift sanctions on Russia in clear message to Trump\\nReuters, Getty Images, Associated Press, Khader Al Za’anoun/CNN, Israel Defense Forces, Palestinian Red Crescent Society\\nHow Gaza’s hospitals became battlegrounds\\nHow the climate crisis fuels gender inequality\\nPhyo Arkar Kyaw Kyaw/Social Media\\nSon says goodbye to mother trapped in Myanmar rubble in emotional farewell video\\nGabby Jones/Bloomberg/Getty Images\\nUncovering security risks in wake of the signal leak\\nPalestinian schoolgirls on impact of war\\nCNN gets rare access embedded with Ecuadorian police and military\\nQuakers say London police arrested six people at meeting on climate change, Gaza\\nKing Charles cancels engagements after experiencing temporary side effects of cancer treatment\\nSearch underway for 4 US Army soldiers missing in Lithuania\\nNorth Korea has sent 3,000 more soldiers to bolster Russia’s war on Ukraine, South Korea says\\nRussian court hands long jail terms to Ukrainian fighters who defended Mariupol\\nEU urges citizens to stockpile 72 hours’ worth of supplies amid war risk\\nIsrael strikes southern Beirut for the first time since November ceasefire\\n‘It starts at the top’: Extremist views are all that many young Israelis have ever known\\n‘No other land:’ Oscar-winning Palestinian director says settler assault won’t push him from his home\\n‘I would prefer this over killing children:’ Why some Israeli teens are choosing jail over the army\\n‘Enough war’: Why Gazans are protesting Hamas now\\nAs Trump offers new nuclear talks, Iran weighs the cost of losing its final leverage\\nAnusak Laowilas/NurPhoto/Getty Images\\nDeadly earthquake strikes Myanmar, Thailand and China\\nRobert Hanashiro/USA Today/Imagn Images\\nSix Russian tourists killed after submarine sinks off Egyptian coast\\nSudan’s army has captured the capital. Is it a turning point in the devastating conflict?\\nSudan’s army returns to capital after nearly two years of civil war\\nPrince Harry ‘in sho\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = llm.create_completion(\n",
        "    prompt=f\"Summarize the following CNN news content:\\n{truncated}\",\n",
        "    max_tokens=512,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "print(output['choices'][0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_KW26TKm9YG",
        "outputId": "0330db48-3544-45f9-e0ff-acf0eb745c89"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 5 prefix-match hit, remaining 915 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =  173649.59 ms\n",
            "llama_perf_context_print: prompt eval time =   78880.34 ms /   915 tokens (   86.21 ms per token,    11.60 tokens per second)\n",
            "llama_perf_context_print:        eval time =   94000.46 ms /   511 runs   (  183.95 ms per token,     5.44 tokens per second)\n",
            "llama_perf_context_print:       total time =  173441.53 ms /  1426 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ots’ after ‘mysterious’ explosion that left him with 1800 lives\n",
            "Sudan’s army ‘behind the scenes’ after a suspected bomber shot\n",
            "Sudan’s army ‘behind the scenes’ after a suspected bomber shot\n",
            "The ‘hit’ was a huge one, and the Sudanese police said the explosives were from a ‘strong’ U.S. aircraft.\n",
            "The ‘hit’ was a huge one, and the Sudanese police said the explosives were from a ‘strong’ U.S. aircraft.\n",
            "Sudan’s army is marching to the capital of Yeniseys, with the police saying it was the result of a bomb blast from a U.S. aircraft.\n",
            "Sudan’s army is marching to the capital of Yeniseys, with the police saying it was the result of a bomb blast from a U.S. aircraft.\n",
            "The ‘hit’ was a huge one, and the Sudanese police said the explosives were from a ‘strong’ U.S. aircraft.\n",
            "Sudan’s army ‘behind the scenes’ after a suspected bomber shot\n",
            "Sudan’s army ‘behind the scenes’ after a suspected bomber shot\n",
            "Sudan’s army is marching to the capital of Yeniseys, with the police saying it was the result of a bomb blast from a U.S. aircraft.\n",
            "The ‘hit’ was a huge one, and the Sudanese police said the explosives were from a ‘strong’ U.S. aircraft.\n",
            "Sudan’s army is marching to the capital of Yeniseys, with the police saying it was the result of a bomb blast from a U.S. aircraft.\n",
            "Sudan’s army is marching to the capital of Yeniseys, with the police saying it was the result of a bomb blast from a U.S. aircraft.\n",
            "Sudan’s army is marching to the capital of Yeniseys, with the police saying it was the result of a bomb blast from a U.S. aircraft.\n",
            "The ‘hit’ was a huge one, and the Sudanese police said the explosives were from a ‘strong’ U.S. aircraft.\n",
            "Sudan’s army is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = (\n",
        "    \"You are a news assistant. Please extract and summarize the main headlines \"\n",
        "    \"and lead paragraphs from the following CNN World News page text. \"\n",
        "    \"Do not include any CSS or JavaScript. Format the output as JSON.\\n\\n\"\n",
        "    f\"{truncated}\"\n",
        ")\n",
        "\n",
        "output = llm.create_completion(\n",
        "    prompt= prompt,\n",
        "    max_tokens=512,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "print(output['choices'][0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2tv12-FnlYh",
        "outputId": "df28eb2c-96cb-4f2e-c9c5-94251ce2c6f6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =  173649.59 ms\n",
            "llama_perf_context_print: prompt eval time =   83461.71 ms /   954 tokens (   87.49 ms per token,    11.43 tokens per second)\n",
            "llama_perf_context_print:        eval time =   93735.53 ms /   511 runs   (  183.44 ms per token,     5.45 tokens per second)\n",
            "llama_perf_context_print:       total time =  177752.86 ms /  1465 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ots’ after three days in jail for ‘unprecedented’ flooding in Kabul\n",
            "Gaza Strikes: ‘I’ve seen the first man in 50 years’\n",
            "Israel’s ‘mortal’ warriors are being ‘mortalized’\n",
            "The world’s youngest country fought for decades to govern itself. Now it’s on the cusp of another civil war\n",
            "The world’s youngest country fought for decades to govern itself. Now it’s on the cusp of another civil war\n",
            "Voices are starting to emerge from quake devastated Myanmar. Here’s what we are hearing\n",
            "Aid workers reported killed and missing in Gaza as Israeli blockade nears one month\n",
            "Danish foreign minister scolds Trump administration for its criticism of Denmark and Greenland\n",
            "From death row to exile, Iranian-Kurdish rapper gives firsthand account of what he calls ‘severe torture’ in Iranian prison\n",
            "European bid for Ukraine ‘reassurance’ force is fraught with risk\n",
            "Meet the conservationist saving gorillas in Uganda’s ‘impenetrable forest’\n",
            "Vast areas of Australia’s Queensland under water after ‘unprecedented’ flooding\n",
            "US defense chief Hegseth vows to counter ‘China’s aggression’ on first Asia visit\n",
            "These 60-year-old geckos could be the world’s oldest\n",
            "European leaders say now not the time to lift sanctions on Russia in clear message to Trump\n",
            "Reuters, Getty Images, Associated Press, Khader Al Za’anoun/CNN, Israel Defense Forces, Palestinian Red Crescent Society\n",
            "How Gaza’s hospitals became battlegrounds\n",
            "How the climate crisis fuels gender equality\n",
            "Phyo Arkar Kyaw Kyaw/Social Media\n",
            "Son says goodbye to mother trapped in Myanmar rubble in emotional farewell video\n",
            "Gabby Jones/Bloomberg/Getty Images\n",
            "Uncovering security risks in wake of the signal leak\n",
            "Palestinian schoolgirls on impact of war\n",
            "CNN gets rare access embedded with Ecuadorian police and military\n",
            "Quakers say London police arrested six people at meeting on climate change, Gaza\n",
            "King Charles cancels engagements after experiencing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NH24AsTQoVNC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}